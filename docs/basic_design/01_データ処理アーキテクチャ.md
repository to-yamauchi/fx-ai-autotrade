# データ処理アーキテクチャ（基本設計）

## ドキュメント情報
- **作成日**: 2025-10-21
- **バージョン**: 1.0
- **種別**: 基本設計書
- **対応する詳細設計**: [01_data_processing_engine.md](../architecture/01_data_processing_engine.md)

---

## 1. 概要

### 1.1 役割

データ処理アーキテクチャは、FX自動売買システムの**データ基盤**として、市場データの取得から標準化までを一貫して担当する基礎層です。

#### 主要な責務

1. **市場データの継続的な取得**
   - ティックデータ取得
     - **バックテスト/モデル作成用**: 月単位zipファイル(csv)から取得
     - **リアルタイムトレード用**: MT5からのリアルタイム取得（100ms周期）
   - 複数時間足データ（D1/H4/H1/M15）の取得と管理
   - 接続断絶時の自動復旧とデータ補完（リアルタイムモード）

2. **生データの加工・変換**
   - ティックデータからOHLC時間足データへの変換
   - 複数時間足の整合性を保った同期データの生成
   - タイムゾーン統一とタイムスタンプの正規化

3. **テクニカル指標の計算**
   - トレンド系指標（EMA、MACD等）の算出
   - オシレーター系指標（RSI、ストキャスティクス等）の算出
   - ボラティリティ系指標（ATR、ボリンジャーバンド等）の算出
   - サポート・レジスタンスレベルの特定

4. **AI解釈可能な形式への標準化**
   - 数値データと解釈テキストを併記した構造化JSON生成
   - 市場構造の抽象化（トレンド方向、強度、パターン等）
   - 一貫性のある命名規則とデータスキーマの維持

5. **データ品質の保証**
   - 異常値検出とフィルタリング（スプレッド異常、価格急変等）
   - データ完全性の検証（欠損チェック、整合性確認）
   - データハッシュによる同一性確認と再現性の担保

#### システム全体における位置づけ

データ処理アーキテクチャは、システムの**情報の入り口**として以下の役割を果たします：

- **AI分析エンジンの前提条件**: AI分析が機能するための高品質な入力データを提供
- **ルールエンジンの判断材料**: Layer 1監視やエントリー判定に必要なリアルタイムデータを供給
- **バックテストの再現性基盤**: 過去データの完全な再現を可能にし、戦略検証の信頼性を支える
- **リスク管理の基礎**: ATR計算やボラティリティ測定により、ポジションサイジングの根拠を提供

#### 提供する価値

1. **確定性**: 同じ入力データからは常に同じ出力を生成し、結果の予測可能性を保証
2. **再現性**: バックテストで過去の市場状況を正確に再現でき、戦略の検証精度を向上
3. **抽象化**: 複雑な市場データをAIが理解しやすい構造化情報に変換し、分析精度を向上
4. **信頼性**: 多重エラーハンドリングと自動復旧により、データ取得の継続性を確保
5. **高速性**: 3秒以内の処理完了により、リアルタイム判断を可能に

#### 設計思想

本アーキテクチャは「**データの正確性がすべての判断の基礎である**」という原則に基づき設計されています：

- **Raw Dataの保全**: 元データを改変せず、変換プロセスを明確に記録
- **処理の透明性**: すべての計算ロジックを明示し、バージョン管理により追跡可能に
- **人間とAIの両方が理解可能**: 数値データだけでなく、解釈テキストも併記することで、検証を容易に
- **フェイルセーフ設計**: データ異常時でも緊急監視（Layer 1）は継続稼働

### 1.2 位置づけ

```
データソース → [データ処理層] → AI分析層
  ↑
  ├─ zipファイル（バックテスト/モデル作成用）
  └─ MT5市場（リアルタイムトレード用）
```

データ処理層は、外部市場データを取得し、システム内部で利用可能な標準形式に変換する責務を持つ

---

## 2. アーキテクチャ構成

### 2.1 全体像

```
┌─────────────────────────────────────────┐
│         データ処理アーキテクチャ           │
├─────────────────────────────────────────┤
│                                         │
│  ┌─────────────────────────────────┐   │
│  │  データソース管理                 │   │
│  │  - zipファイル読み込み           │   │
│  │  - MT5接続（リアルタイム用）     │   │
│  │  - 再接続制御                    │   │
│  └─────────────────────────────────┘   │
│            ↓                            │
│  ┌─────────────────────────────────┐   │
│  │  データ取得                       │   │
│  │  - zip: 月単位ティックデータ     │   │
│  │  - MT5: リアルタイムティック     │   │
│  │  - OHLC時間足データ              │   │
│  └─────────────────────────────────┘   │
│            ↓                            │
│  ┌─────────────────────────────────┐   │
│  │  時間足変換                       │   │
│  │  - D1, H4, H1, M15への変換       │   │
│  └─────────────────────────────────┘   │
│            ↓                            │
│  ┌─────────────────────────────────┐   │
│  │  テクニカル指標計算               │   │
│  │  - トレンド系 (EMA, MACD)        │   │
│  │  - オシレーター系 (RSI)          │   │
│  │  - ボラティリティ系 (ATR, BB)    │   │
│  │  - サポレジ (ピボット等)          │   │
│  └─────────────────────────────────┘   │
│            ↓                            │
│  ┌─────────────────────────────────┐   │
│  │  データ標準化                     │   │
│  │  - AI解釈可能な形式に変換         │   │
│  │  - データハッシュ生成             │   │
│  └─────────────────────────────────┘   │
│            ↓                            │
│       標準化データJSON                   │
└─────────────────────────────────────────┘
```

### 2.2 主要コンポーネント

| コンポーネント | 責務 | 主要技術 |
|--------------|------|---------|
| **データソース管理** | zipファイル読み込み、MT5接続維持 | zipfile, MetaTrader5 API |
| **データ取得** | 市場データ取得 | csv読み込み、API呼び出し |
| **時間足変換** | ティック→OHLC変換 | pandas |
| **指標計算** | テクニカル指標算出 | TA-Lib / pandas-ta |
| **標準化** | JSON形式変換 | Python dict/json |

---

## 3. データフロー

### 3.1 リアルタイムデータフロー（実運用モード）

```
100msごと:
  MT5 → ティック取得 → Layer 1監視用

1分ごと:
  MT5 → 時間足更新チェック
      → 更新あり → テクニカル指標再計算
                → 標準化データ更新
                → 後続処理へ通知

定時実行時 (AI分析時):
  MT5 → 全時間足データ取得
      → テクニカル指標計算
      → 標準化データ生成
      → AI分析エンジンへ渡す
```

### 3.1b バックテストデータフロー（モデル作成モード）

```
バックテスト開始:
  指定期間の月を特定
      → 該当zipファイルを順次読み込み
      → ティックデータを時系列結合

指定日時ごと:
  ティックデータ → 時間足変換
                → テクニカル指標計算
                → 標準化データ生成
                → AI分析/バックテスト実行
```

### 3.2 データ変換の流れ

```
ティックデータ (bid, ask, time)
  ↓ 時間足変換
OHLC時系列データ (4時間足)
  ├→ D1 (30本)
  ├→ H4 (50本)
  ├→ H1 (100本)
  └→ M15 (100本)
  ↓ 指標計算
テクニカル指標
  ├→ トレンド系 (EMA20, EMA50, MACD)
  ├→ オシレーター系 (RSI, ストキャス)
  ├→ ボラティリティ系 (ATR, BB)
  └→ サポレジ (ピボット, フィボナッチ)
  ↓ 標準化
AI解釈可能なJSON
  ├→ 市場構造の解釈
  ├→ テクニカルサマリー
  ├→ 重要レベル
  └→ 直近の値動き
```

---

## 4. 設計原則

### 4.1 確定性

**原則**: 同じ入力から常に同じ出力を生成

**実現方法**:
- 指標計算ロジックの固定化
- タイムゾーンの統一
- データハッシュによる同一性確認

### 4.2 再現性

**原則**: バックテストで過去データを完全に再現可能

**実現方法**:
- 全データの記録
- 計算ロジックのバージョン管理
- タイムスタンプの正確な保存

### 4.3 標準化

**原則**: AIが解釈しやすい統一フォーマット

**実現方法**:
- 数値データと解釈テキストの併記
- 階層化されたJSON構造
- 一貫した命名規則

---

## 5. 取得データ仕様

### 5.1 時間足データ

| 時間足 | 取得本数 | 主な用途 |
|--------|----------|----------|
| **D1 (日足)** | 30本 | 長期トレンド判定、サポレジ算出 |
| **H4 (4時間足)** | 50本 | 中期トレンド確認、EMA配列 |
| **H1 (1時間足)** | 100本 | メイン分析、エントリー判定 |
| **M15 (15分足)** | 100本 | 短期シグナル、最終判断 |

### 5.2 テクニカル指標

| カテゴリ | 指標 | パラメータ | 用途 |
|---------|------|-----------|------|
| **トレンド系** | EMA | 20, 50 | トレンド方向判定 |
| | MACD | 12, 26, 9 | モメンタム確認 |
| **オシレーター系** | RSI | 14 | 過熱感判定 |
| | ストキャス | 5, 3, 3 | 補助シグナル |
| **ボラティリティ系** | ATR | 14 | ポジションサイズ調整 |
| | ボリンジャーバンド | 20, 2σ | レンジ判定 |
| **サポレジ** | ピボットポイント | 標準 | 重要レベル |
| | フィボナッチ | 主要レベル | リトレースメント |

---

## 6. 標準化データ構造

### 6.1 データ構造概要

標準化データは以下の5つのセクションで構成:

```json
{
  "metadata": "メタ情報",
  "market_structure": "市場構造の解釈",
  "technical_summary": "テクニカル指標のサマリー",
  "key_levels": "重要な価格レベル",
  "recent_price_action": "直近の値動き"
}
```

### 6.2 主要セクション

| セクション | 内容 | 目的 |
|-----------|------|------|
| **metadata** | タイムスタンプ、通貨ペア、データハッシュ | トレーサビリティ |
| **market_structure** | トレンド方向、強度、パターン | 大局観の提供 |
| **technical_summary** | 各指標の値と解釈 | 詳細分析材料 |
| **key_levels** | サポート、レジスタンス | エントリー・決済判断 |
| **recent_price_action** | 直近の足の動き | 短期トレンド把握 |

---

## 7. 品質管理

### 7.1 異常値検出

**監視項目**:
- スプレッド異常 (>20pips)
- 価格の急激な変動 (0.1秒で30pips以上)
- データ欠損
- タイムスタンプ不整合

**対応**:
- 異常値の記録とアラート
- 一時的なエントリー停止
- Layer 1監視は継続

### 7.2 データ完全性

**検証内容**:
- 全時間足データの存在確認
- 全指標の計算完了確認
- 欠損値のチェック

**不完全時の対応**:
- エントリー判断の一時停止
- 緊急監視 (Layer 1) は継続稼働
- データ復旧後に自動再開

---

## 8. パフォーマンス要件

### 8.1 処理速度目標

| 処理 | 目標時間 | 重要度 |
|------|---------|--------|
| **ティック取得** | 100ms以内 | 最高 (Layer 1用) |
| **時間足変換** | 500ms以内 | 高 |
| **テクニカル指標計算** | 1秒以内 | 高 |
| **標準化データ生成** | 1.5秒以内 | 中 |
| **合計処理時間** | 3秒以内 | - |

### 8.2 信頼性目標

| 指標 | 目標値 |
|------|--------|
| **データ取得成功率** | 99.5%以上 |
| **接続復旧時間** | 3秒以内 |
| **稼働率** | 99%以上 |

---

## 9. エラーハンドリング

### 9.1 接続エラー

**対応フロー**:
```
接続エラー検出
  ↓
再接続試行 (最大3回、1秒間隔)
  ↓ 成功
通常処理再開
  ↓ 失敗
アラート送信
Layer 1は独立稼働継続
```

### 9.2 データ取得エラー

**対応フロー**:
```
データ取得失敗
  ↓
直近の正常データを使用
異常フラグを付与
  ↓
エントリー判断を一時停止
Layer 1監視は継続
  ↓
次回取得で復旧確認
```

---

## 10. 技術選定

### 10.1 主要ライブラリ

| ライブラリ | 用途 | 選定理由 |
|-----------|------|---------|
| **MetaTrader5** | MT5 API | 公式Pythonライブラリ |
| **pandas** | データ処理 | 時系列データ処理に最適 |
| **numpy** | 数値計算 | 高速な配列演算 |
| **TA-Lib** | テクニカル指標 | 標準的な指標ライブラリ |

### 10.2 代替技術

| 用途 | 代替案 | 検討理由 |
|------|--------|---------|
| テクニカル指標 | pandas-ta | TA-Libのインストールが困難な場合 |
| データ処理 | polars | 超高速処理が必要な場合 |

---

## 11. まとめ

### 11.1 アーキテクチャの特徴

1. **確定的処理**: 同じ入力から同じ出力を保証
2. **再現性**: バックテスト検証を可能にする設計
3. **標準化**: AI解釈可能な統一フォーマット
4. **高信頼性**: 多重エラーハンドリング
5. **高速処理**: 3秒以内の処理完了

### 11.2 次のステップ

詳細な実装仕様については、以下を参照:
- [詳細設計書: データ処理エンジン](../architecture/01_data_processing_engine.md)
- [データ仕様詳細](../architecture/06_data_specifications.md)

---

**本書は基本設計レベルのアーキテクチャを示しています。**
**実装の詳細は詳細設計書を参照してください。**
