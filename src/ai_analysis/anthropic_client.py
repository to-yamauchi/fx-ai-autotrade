"""
========================================
Anthropic Claude APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
========================================

ãƒ•ã‚¡ã‚¤ãƒ«å: anthropic_client.py
ãƒ‘ã‚¹: src/ai_analysis/anthropic_client.py

ã€æ¦‚è¦ã€‘
Anthropic Claude APIã‚’ä½¿ç”¨ã—ã¦LLMãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆã™ã‚‹ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã§ã™ã€‚
BaseLLMClientã‚’ç¶™æ‰¿ã—ã€çµ±ä¸€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’å®Ÿè£…ã—ã¾ã™ã€‚

ã€å¯¾å¿œãƒ¢ãƒ‡ãƒ«ã€‘
- claude-sonnet-4-5 (æœ€æ–°ãƒ»æœ€é«˜æ€§èƒ½)
- claude-sonnet-4
- claude-haiku-4
- claude-opus-4

æœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«ä¸€è¦§: https://docs.anthropic.com/en/docs/about-claude/models

ã€ä½¿ç”¨ä¾‹ã€‘
```python
from src.ai_analysis.anthropic_client import AnthropicClient

client = AnthropicClient(api_key="your_api_key")
response = client.generate_response(
    prompt="Analyze this market data...",
    model="claude-sonnet-4-5",
    temperature=0.3,
    max_tokens=2000
)
```

ã€ä½œæˆæ—¥ã€‘2025-10-23
"""

from typing import Optional
import logging
from anthropic import Anthropic
from src.ai_analysis.base_llm_client import BaseLLMClient


class AnthropicClient(BaseLLMClient):
    """
    Anthropic Claude APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ

    Anthropic APIã‚’ä½¿ç”¨ã—ã¦LLMãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
    """

    def __init__(self, api_key: str):
        """
        AnthropicClientã®åˆæœŸåŒ–

        Args:
            api_key: Anthropic APIã‚­ãƒ¼
        """
        super().__init__(api_key)
        self.client = Anthropic(api_key=api_key)
        self.logger.info("Anthropic client initialized")

    def generate_response(
        self,
        prompt: str,
        model: str,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        **kwargs
    ) -> str:
        """
        Anthropic APIã‹ã‚‰ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆ

        Args:
            prompt: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ã‚­ã‚¹ãƒˆ
            model: ãƒ¢ãƒ‡ãƒ«åï¼ˆä¾‹: claude-sonnet-4-5, claude-haiku-4ï¼‰
            temperature: æ¸©åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆ0.0-1.0ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1.0ï¼‰
            max_tokens: æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°ï¼ˆNoneã®å ´åˆ: 4096ï¼‰
            **kwargs: ãã®ä»–ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆtop_p, top_k, etc.ï¼‰

        Returns:
            str: ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ

        Raises:
            Exception: APIå‘¼ã³å‡ºã—ãŒå¤±æ•—ã—ãŸå ´åˆ
        """
        try:
            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
            params = {
                "model": model,
                "messages": [
                    {"role": "user", "content": prompt}
                ],
                # Anthropic APIã¯max_tokensãŒå¿…é ˆ
                # Noneã®å ´åˆã¯4096ï¼ˆClaude-4ã®æ¨å¥¨æœ€å¤§å€¤ï¼‰ã‚’ä½¿ç”¨
                "max_tokens": max_tokens if max_tokens is not None else 4096,
            }

            if temperature is not None:
                params["temperature"] = temperature

            # ãã®ä»–ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒãƒ¼ã‚¸
            params.update(kwargs)

            self.logger.debug(
                f"Anthropic API request: model={model}, "
                f"temperature={temperature}, max_tokens={max_tokens}"
            )

            # APIå‘¼ã³å‡ºã—
            response = self.client.messages.create(**params)

            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
            if not response.content:
                raise ValueError("Anthropic API returned no content")

            # Claudeã¯è¤‡æ•°ã®content blockã‚’è¿”ã™å¯èƒ½æ€§ãŒã‚ã‚‹ãŒã€é€šå¸¸ã¯1ã¤
            text = "".join([block.text for block in response.content if hasattr(block, 'text')])

            # stop_reasonã‚’ãƒã‚§ãƒƒã‚¯
            stop_reason = response.stop_reason
            if stop_reason == "max_tokens":
                self.logger.warning(
                    f"Response was truncated due to max_tokens limit. "
                    f"Current max_tokens: {max_tokens}. "
                    f"Consider increasing max_tokens in .env"
                )
            elif stop_reason == "stop_sequence":
                # æ­£å¸¸çµ‚äº†ï¼ˆstop sequenceã«é”ã—ãŸï¼‰
                pass
            elif stop_reason == "end_turn":
                # æ­£å¸¸çµ‚äº†ï¼ˆä¼šè©±ãŒçµ‚äº†ï¼‰
                pass

            self.logger.debug(
                f"Anthropic API response received: "
                f"stop_reason={stop_reason}, "
                f"length={len(text)} chars"
            )

            return text

        except Exception as e:
            self.logger.error(f"Anthropic API error: {e}")
            raise

    def test_connection(self, verbose: bool = False) -> bool:
        """
        Anthropic APIã¸ã®æ¥ç¶šãƒ†ã‚¹ãƒˆ

        Args:
            verbose: è©³ç´°ãªãƒ­ã‚°ã‚’å‡ºåŠ›ã™ã‚‹ã‹ã©ã†ã‹

        Returns:
            bool: True=æ¥ç¶šæˆåŠŸ, False=æ¥ç¶šå¤±æ•—
        """
        try:
            if verbose:
                print("ğŸ”Œ Anthropic APIæ¥ç¶šãƒ†ã‚¹ãƒˆä¸­...", end='', flush=True)

            # ç°¡å˜ãªãƒ†ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é€ä¿¡
            test_prompt = "Hello, this is a connection test. Please respond with 'OK'."
            response = self.generate_response(
                prompt=test_prompt,
                model="claude-haiku-4",  # æœ€ã‚‚å®‰ä¾¡ã§é«˜é€Ÿãªãƒ¢ãƒ‡ãƒ«ã§ãƒ†ã‚¹ãƒˆ
                max_tokens=10
            )

            if response:
                if verbose:
                    print(" âœ“ æ¥ç¶šæˆåŠŸ")
                self.logger.info("Anthropic API connection test: SUCCESS")
                return True
            else:
                if verbose:
                    print(" âœ— æ¥ç¶šå¤±æ•—")
                self.logger.error("Anthropic API connection test: FAILED (empty response)")
                return False

        except Exception as e:
            if verbose:
                print(f" âœ— æ¥ç¶šå¤±æ•—: {e}")
            self.logger.error(f"Anthropic API connection test: FAILED - {e}")
            return False

    def get_provider_name(self) -> str:
        """
        ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åã‚’å–å¾—

        Returns:
            str: "anthropic"
        """
        return "anthropic"
